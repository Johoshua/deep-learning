{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 2:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 3 Max Value: 219\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxv43XI8p802nQmEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146e5da0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 2\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = 0.1 + (x - x.min())*0.8/(x.max()-x.min())\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = dict()\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    encode = False\n",
    "    for label in x:\n",
    "        if label not in encoded_labels:\n",
    "            encode = True\n",
    "            encoded_labels[label] = []\n",
    "\n",
    "    if encode:       \n",
    "        to_encode = []\n",
    "        for key, value in encoded_labels.items():\n",
    "            to_encode.append(key)\n",
    "        encoder = preprocessing.LabelBinarizer()\n",
    "        encoder.fit(to_encode)\n",
    "        new_labels = encoder.transform(to_encode)\n",
    "        for i in range(len(new_labels)):\n",
    "            encoded_labels[to_encode[i]] = new_labels[i]\n",
    "    \n",
    "    for label in x: \n",
    "        labels.append(encoded_labels[label])\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    return np.asarray(labels, dtype=np.float32)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None]\n",
    "    for s in image_shape:\n",
    "        shape.append(s)\n",
    "    \n",
    "    return tf.placeholder(tf.float32, shape=shape, name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list() \n",
    "        \n",
    "    w = tf.Variable(tf.random_normal([conv_ksize[0],conv_ksize[1], x_shape[3] , conv_num_outputs], mean=0.0, stddev=0.05))\n",
    "    b = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, w, [1,conv_strides[0],conv_strides[1],1], 'SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, b)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    return tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1], 1], \\\n",
    "                          strides=[1, pool_strides[0], pool_strides[1], 1],\\\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    size = shape[1]*shape[2]*shape[3]\n",
    "    return tf.reshape(x_tensor, [-1, size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dims = x_tensor.get_shape().as_list()[1] #[0] is batch size\n",
    "    w = tf.Variable(tf.random_normal([dims, num_outputs], mean=0.0, stddev=0.05))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    res = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    return tf.nn.relu(res)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    w = tf.Variable(tf.random_normal([x_tensor.get_shape().as_list()[1], num_outputs], mean=0.0, stddev=0.05))\n",
    "    b = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    return tf.add(tf.matmul(x_tensor, w),b)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_outputs1 = 16\n",
    "    conv_ksize1 = (5, 5)\n",
    "    conv_strides1 = (1, 1)\n",
    "    pool_k1 = (2, 2)\n",
    "    pool_strides1 = (2, 2)\n",
    "    conv_net = conv2d_maxpool(x, conv_outputs1, conv_ksize1, conv_strides1, pool_k1, pool_strides1)\n",
    "    \n",
    "    conv_outputs2 = 64\n",
    "    conv_ksize2 = (2, 2)\n",
    "    conv_strides2 = (1, 1)\n",
    "    pool_k2 = (2, 2)\n",
    "    pool_strides2 = (2, 2)\n",
    "    conv_net = conv2d_maxpool(conv_net, conv_outputs2, conv_ksize2, conv_strides2, pool_k2, pool_strides2)\n",
    "    \n",
    "    conv_outputs3 = 128\n",
    "    conv_ksize3 = (2, 2)\n",
    "    conv_strides3 = (1, 1)\n",
    "    pool_k3 = (2, 2)\n",
    "    pool_strides3 = (1, 1)\n",
    "    conv_net = conv2d_maxpool(conv_net, conv_outputs2, conv_ksize2, conv_strides2, pool_k2, pool_strides2)\n",
    "    \n",
    "  \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    conv_net = flatten(conv_net)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    conv_net = fully_conn(conv_net, 100)\n",
    "    conv_net = tf.nn.dropout(conv_net, keep_prob)\n",
    "    conv_net = fully_conn(conv_net, 50)\n",
    "    conv_net = tf.nn.dropout(conv_net, keep_prob)\n",
    "    conv_net = fully_conn(conv_net, 200)\n",
    "    conv_net = tf.nn.dropout(conv_net, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    return output(conv_net, 10)\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    optimizer = session.run(\n",
    "        [optimizer],\n",
    "        feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    valid_feed_dict = {x: valid_features, y: valid_labels, keep_prob: 1.0}\n",
    "    train_feed_dict = {x: feature_batch, y: label_batch, keep_prob: 1.0}\n",
    "\n",
    "    validation_accuracy = session.run(accuracy, feed_dict = valid_feed_dict)\n",
    "    validation_loss = session.run(cost, feed_dict=valid_feed_dict)  \n",
    "    train_loss = session.run(cost, feed_dict=train_feed_dict) \n",
    "    \n",
    "    print('validation accuracy {}'.format(validation_accuracy), 'validation loss {}'.format(validation_loss))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 40\n",
    "batch_size = 128\n",
    "keep_probability = 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  validation accuracy 0.12600000202655792 validation loss 2.2808642387390137\n",
      "Epoch  2, CIFAR-10 Batch 1:  validation accuracy 0.15520000457763672 validation loss 2.215158700942993\n",
      "Epoch  3, CIFAR-10 Batch 1:  validation accuracy 0.1477999985218048 validation loss 2.231182336807251\n",
      "Epoch  4, CIFAR-10 Batch 1:  validation accuracy 0.1454000025987625 validation loss 2.2092812061309814\n",
      "Epoch  5, CIFAR-10 Batch 1:  validation accuracy 0.18520000576972961 validation loss 2.075110673904419\n",
      "Epoch  6, CIFAR-10 Batch 1:  validation accuracy 0.22360000014305115 validation loss 1.955350399017334\n",
      "Epoch  7, CIFAR-10 Batch 1:  validation accuracy 0.266400009393692 validation loss 1.8116072416305542\n",
      "Epoch  8, CIFAR-10 Batch 1:  validation accuracy 0.2881999909877777 validation loss 1.7848438024520874\n",
      "Epoch  9, CIFAR-10 Batch 1:  validation accuracy 0.3109999895095825 validation loss 1.7561644315719604\n",
      "Epoch 10, CIFAR-10 Batch 1:  validation accuracy 0.32280001044273376 validation loss 1.701544165611267\n",
      "Epoch 11, CIFAR-10 Batch 1:  validation accuracy 0.33959999680519104 validation loss 1.6969174146652222\n",
      "Epoch 12, CIFAR-10 Batch 1:  validation accuracy 0.3490000069141388 validation loss 1.6692653894424438\n",
      "Epoch 13, CIFAR-10 Batch 1:  validation accuracy 0.36579999327659607 validation loss 1.6388871669769287\n",
      "Epoch 14, CIFAR-10 Batch 1:  validation accuracy 0.36500000953674316 validation loss 1.637764811515808\n",
      "Epoch 15, CIFAR-10 Batch 1:  validation accuracy 0.3734000027179718 validation loss 1.6206868886947632\n",
      "Epoch 16, CIFAR-10 Batch 1:  validation accuracy 0.38940000534057617 validation loss 1.5754984617233276\n",
      "Epoch 17, CIFAR-10 Batch 1:  validation accuracy 0.3885999917984009 validation loss 1.565158486366272\n",
      "Epoch 18, CIFAR-10 Batch 1:  validation accuracy 0.4235999882221222 validation loss 1.5139858722686768\n",
      "Epoch 19, CIFAR-10 Batch 1:  validation accuracy 0.41780000925064087 validation loss 1.548941969871521\n",
      "Epoch 20, CIFAR-10 Batch 1:  validation accuracy 0.41839998960494995 validation loss 1.5044785737991333\n",
      "Epoch 21, CIFAR-10 Batch 1:  validation accuracy 0.4442000091075897 validation loss 1.4609922170639038\n",
      "Epoch 22, CIFAR-10 Batch 1:  validation accuracy 0.45399999618530273 validation loss 1.453316330909729\n",
      "Epoch 23, CIFAR-10 Batch 1:  validation accuracy 0.48159998655319214 validation loss 1.3995906114578247\n",
      "Epoch 24, CIFAR-10 Batch 1:  validation accuracy 0.4765999913215637 validation loss 1.4208835363388062\n",
      "Epoch 25, CIFAR-10 Batch 1:  validation accuracy 0.48660001158714294 validation loss 1.4052155017852783\n",
      "Epoch 26, CIFAR-10 Batch 1:  validation accuracy 0.45739999413490295 validation loss 1.454054355621338\n",
      "Epoch 27, CIFAR-10 Batch 1:  validation accuracy 0.4936000108718872 validation loss 1.3847237825393677\n",
      "Epoch 28, CIFAR-10 Batch 1:  validation accuracy 0.49480000138282776 validation loss 1.3929201364517212\n",
      "Epoch 29, CIFAR-10 Batch 1:  validation accuracy 0.49239999055862427 validation loss 1.4067275524139404\n",
      "Epoch 30, CIFAR-10 Batch 1:  validation accuracy 0.45559999346733093 validation loss 1.4829779863357544\n",
      "Epoch 31, CIFAR-10 Batch 1:  validation accuracy 0.5210000276565552 validation loss 1.3276612758636475\n",
      "Epoch 32, CIFAR-10 Batch 1:  validation accuracy 0.5041999816894531 validation loss 1.3883459568023682\n",
      "Epoch 33, CIFAR-10 Batch 1:  validation accuracy 0.5238000154495239 validation loss 1.3470425605773926\n",
      "Epoch 34, CIFAR-10 Batch 1:  validation accuracy 0.490200012922287 validation loss 1.405746340751648\n",
      "Epoch 35, CIFAR-10 Batch 1:  validation accuracy 0.5266000032424927 validation loss 1.3082953691482544\n",
      "Epoch 36, CIFAR-10 Batch 1:  validation accuracy 0.5293999910354614 validation loss 1.2973698377609253\n",
      "Epoch 37, CIFAR-10 Batch 1:  validation accuracy 0.5212000012397766 validation loss 1.3326066732406616\n",
      "Epoch 38, CIFAR-10 Batch 1:  validation accuracy 0.5257999897003174 validation loss 1.3452506065368652\n",
      "Epoch 39, CIFAR-10 Batch 1:  validation accuracy 0.5407999753952026 validation loss 1.3079161643981934\n",
      "Epoch 40, CIFAR-10 Batch 1:  validation accuracy 0.5370000004768372 validation loss 1.317102313041687\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #tf.initialize_all_variables\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  validation accuracy 0.0997999981045723 validation loss 2.4276669025421143\n",
      "Epoch  1, CIFAR-10 Batch 2:  validation accuracy 0.10199999809265137 validation loss 2.333904266357422\n",
      "Epoch  1, CIFAR-10 Batch 3:  validation accuracy 0.14319999516010284 validation loss 2.2813596725463867\n",
      "Epoch  1, CIFAR-10 Batch 4:  validation accuracy 0.1972000002861023 validation loss 2.2185897827148438\n",
      "Epoch  1, CIFAR-10 Batch 5:  validation accuracy 0.22499999403953552 validation loss 1.9817591905593872\n",
      "Epoch  2, CIFAR-10 Batch 1:  validation accuracy 0.22939999401569366 validation loss 1.9526917934417725\n",
      "Epoch  2, CIFAR-10 Batch 2:  validation accuracy 0.26260000467300415 validation loss 1.9030413627624512\n",
      "Epoch  2, CIFAR-10 Batch 3:  validation accuracy 0.2694000005722046 validation loss 1.8554749488830566\n",
      "Epoch  2, CIFAR-10 Batch 4:  validation accuracy 0.30399999022483826 validation loss 1.8058902025222778\n",
      "Epoch  2, CIFAR-10 Batch 5:  validation accuracy 0.28439998626708984 validation loss 1.8371357917785645\n",
      "Epoch  3, CIFAR-10 Batch 1:  validation accuracy 0.3287999927997589 validation loss 1.7376890182495117\n",
      "Epoch  3, CIFAR-10 Batch 2:  validation accuracy 0.33000001311302185 validation loss 1.722015619277954\n",
      "Epoch  3, CIFAR-10 Batch 3:  validation accuracy 0.33079999685287476 validation loss 1.6952877044677734\n",
      "Epoch  3, CIFAR-10 Batch 4:  validation accuracy 0.3734000027179718 validation loss 1.6528457403182983\n",
      "Epoch  3, CIFAR-10 Batch 5:  validation accuracy 0.37940001487731934 validation loss 1.6302776336669922\n",
      "Epoch  4, CIFAR-10 Batch 1:  validation accuracy 0.39640000462532043 validation loss 1.6226634979248047\n",
      "Epoch  4, CIFAR-10 Batch 2:  validation accuracy 0.4047999978065491 validation loss 1.5459187030792236\n",
      "Epoch  4, CIFAR-10 Batch 3:  validation accuracy 0.40619999170303345 validation loss 1.5777692794799805\n",
      "Epoch  4, CIFAR-10 Batch 4:  validation accuracy 0.44339999556541443 validation loss 1.4980835914611816\n",
      "Epoch  4, CIFAR-10 Batch 5:  validation accuracy 0.4562000036239624 validation loss 1.466879963874817\n",
      "Epoch  5, CIFAR-10 Batch 1:  validation accuracy 0.44620001316070557 validation loss 1.48494291305542\n",
      "Epoch  5, CIFAR-10 Batch 2:  validation accuracy 0.4474000036716461 validation loss 1.4439923763275146\n",
      "Epoch  5, CIFAR-10 Batch 3:  validation accuracy 0.46399998664855957 validation loss 1.424979329109192\n",
      "Epoch  5, CIFAR-10 Batch 4:  validation accuracy 0.47920000553131104 validation loss 1.391622543334961\n",
      "Epoch  5, CIFAR-10 Batch 5:  validation accuracy 0.48579999804496765 validation loss 1.3812512159347534\n",
      "Epoch  6, CIFAR-10 Batch 1:  validation accuracy 0.5054000020027161 validation loss 1.3572474718093872\n",
      "Epoch  6, CIFAR-10 Batch 2:  validation accuracy 0.4797999858856201 validation loss 1.3554441928863525\n",
      "Epoch  6, CIFAR-10 Batch 3:  validation accuracy 0.48260000348091125 validation loss 1.3547585010528564\n",
      "Epoch  6, CIFAR-10 Batch 4:  validation accuracy 0.5001999735832214 validation loss 1.3347318172454834\n",
      "Epoch  6, CIFAR-10 Batch 5:  validation accuracy 0.5148000121116638 validation loss 1.3019098043441772\n",
      "Epoch  7, CIFAR-10 Batch 1:  validation accuracy 0.526199996471405 validation loss 1.3007994890213013\n",
      "Epoch  7, CIFAR-10 Batch 2:  validation accuracy 0.49399998784065247 validation loss 1.3238928318023682\n",
      "Epoch  7, CIFAR-10 Batch 3:  validation accuracy 0.4973999857902527 validation loss 1.3295269012451172\n",
      "Epoch  7, CIFAR-10 Batch 4:  validation accuracy 0.5135999917984009 validation loss 1.3129602670669556\n",
      "Epoch  7, CIFAR-10 Batch 5:  validation accuracy 0.520799994468689 validation loss 1.2790838479995728\n",
      "Epoch  8, CIFAR-10 Batch 1:  validation accuracy 0.5418000221252441 validation loss 1.2598544359207153\n",
      "Epoch  8, CIFAR-10 Batch 2:  validation accuracy 0.5278000235557556 validation loss 1.2496148347854614\n",
      "Epoch  8, CIFAR-10 Batch 3:  validation accuracy 0.5303999781608582 validation loss 1.2666274309158325\n",
      "Epoch  8, CIFAR-10 Batch 4:  validation accuracy 0.5523999929428101 validation loss 1.2248798608779907\n",
      "Epoch  8, CIFAR-10 Batch 5:  validation accuracy 0.545799970626831 validation loss 1.2376607656478882\n",
      "Epoch  9, CIFAR-10 Batch 1:  validation accuracy 0.5547999739646912 validation loss 1.2142103910446167\n",
      "Epoch  9, CIFAR-10 Batch 2:  validation accuracy 0.5419999957084656 validation loss 1.2376868724822998\n",
      "Epoch  9, CIFAR-10 Batch 3:  validation accuracy 0.5690000057220459 validation loss 1.1927226781845093\n",
      "Epoch  9, CIFAR-10 Batch 4:  validation accuracy 0.5753999948501587 validation loss 1.1768704652786255\n",
      "Epoch  9, CIFAR-10 Batch 5:  validation accuracy 0.5562000274658203 validation loss 1.2088634967803955\n",
      "Epoch 10, CIFAR-10 Batch 1:  validation accuracy 0.5699999928474426 validation loss 1.2110528945922852\n",
      "Epoch 10, CIFAR-10 Batch 2:  validation accuracy 0.5690000057220459 validation loss 1.1747801303863525\n",
      "Epoch 10, CIFAR-10 Batch 3:  validation accuracy 0.5569999814033508 validation loss 1.189940333366394\n",
      "Epoch 10, CIFAR-10 Batch 4:  validation accuracy 0.579200029373169 validation loss 1.1546027660369873\n",
      "Epoch 10, CIFAR-10 Batch 5:  validation accuracy 0.5809999704360962 validation loss 1.1487152576446533\n",
      "Epoch 11, CIFAR-10 Batch 1:  validation accuracy 0.5834000110626221 validation loss 1.1687849760055542\n",
      "Epoch 11, CIFAR-10 Batch 2:  validation accuracy 0.5817999839782715 validation loss 1.1454607248306274\n",
      "Epoch 11, CIFAR-10 Batch 3:  validation accuracy 0.5601999759674072 validation loss 1.2116236686706543\n",
      "Epoch 11, CIFAR-10 Batch 4:  validation accuracy 0.5950000286102295 validation loss 1.1286444664001465\n",
      "Epoch 11, CIFAR-10 Batch 5:  validation accuracy 0.5601999759674072 validation loss 1.197805643081665\n",
      "Epoch 12, CIFAR-10 Batch 1:  validation accuracy 0.5759999752044678 validation loss 1.1683413982391357\n",
      "Epoch 12, CIFAR-10 Batch 2:  validation accuracy 0.5752000212669373 validation loss 1.1695281267166138\n",
      "Epoch 12, CIFAR-10 Batch 3:  validation accuracy 0.5899999737739563 validation loss 1.1256630420684814\n",
      "Epoch 12, CIFAR-10 Batch 4:  validation accuracy 0.6075999736785889 validation loss 1.1130808591842651\n",
      "Epoch 12, CIFAR-10 Batch 5:  validation accuracy 0.5852000117301941 validation loss 1.125977873802185\n",
      "Epoch 13, CIFAR-10 Batch 1:  validation accuracy 0.603600025177002 validation loss 1.1120986938476562\n",
      "Epoch 13, CIFAR-10 Batch 2:  validation accuracy 0.5906000137329102 validation loss 1.126410961151123\n",
      "Epoch 13, CIFAR-10 Batch 3:  validation accuracy 0.6003999710083008 validation loss 1.1091078519821167\n",
      "Epoch 13, CIFAR-10 Batch 4:  validation accuracy 0.5896000266075134 validation loss 1.147815465927124\n",
      "Epoch 13, CIFAR-10 Batch 5:  validation accuracy 0.5702000260353088 validation loss 1.1727098226547241\n",
      "Epoch 14, CIFAR-10 Batch 1:  validation accuracy 0.5947999954223633 validation loss 1.1468998193740845\n",
      "Epoch 14, CIFAR-10 Batch 2:  validation accuracy 0.6074000000953674 validation loss 1.089700698852539\n",
      "Epoch 14, CIFAR-10 Batch 3:  validation accuracy 0.6123999953269958 validation loss 1.079359531402588\n",
      "Epoch 14, CIFAR-10 Batch 4:  validation accuracy 0.6110000014305115 validation loss 1.0937473773956299\n",
      "Epoch 14, CIFAR-10 Batch 5:  validation accuracy 0.6092000007629395 validation loss 1.0941299200057983\n",
      "Epoch 15, CIFAR-10 Batch 1:  validation accuracy 0.6144000291824341 validation loss 1.1109347343444824\n",
      "Epoch 15, CIFAR-10 Batch 2:  validation accuracy 0.6050000190734863 validation loss 1.1065278053283691\n",
      "Epoch 15, CIFAR-10 Batch 3:  validation accuracy 0.6281999945640564 validation loss 1.0595308542251587\n",
      "Epoch 15, CIFAR-10 Batch 4:  validation accuracy 0.621399998664856 validation loss 1.076737642288208\n",
      "Epoch 15, CIFAR-10 Batch 5:  validation accuracy 0.6172000169754028 validation loss 1.0689914226531982\n",
      "Epoch 16, CIFAR-10 Batch 1:  validation accuracy 0.614799976348877 validation loss 1.0870765447616577\n",
      "Epoch 16, CIFAR-10 Batch 2:  validation accuracy 0.6212000250816345 validation loss 1.0676822662353516\n",
      "Epoch 16, CIFAR-10 Batch 3:  validation accuracy 0.6313999891281128 validation loss 1.0628520250320435\n",
      "Epoch 16, CIFAR-10 Batch 4:  validation accuracy 0.6227999925613403 validation loss 1.0634644031524658\n",
      "Epoch 16, CIFAR-10 Batch 5:  validation accuracy 0.59579998254776 validation loss 1.134284257888794\n",
      "Epoch 17, CIFAR-10 Batch 1:  validation accuracy 0.6209999918937683 validation loss 1.0958199501037598\n",
      "Epoch 17, CIFAR-10 Batch 2:  validation accuracy 0.620199978351593 validation loss 1.0824836492538452\n",
      "Epoch 17, CIFAR-10 Batch 3:  validation accuracy 0.6158000230789185 validation loss 1.0701733827590942\n",
      "Epoch 17, CIFAR-10 Batch 4:  validation accuracy 0.6101999878883362 validation loss 1.1056357622146606\n",
      "Epoch 17, CIFAR-10 Batch 5:  validation accuracy 0.6218000054359436 validation loss 1.0572134256362915\n",
      "Epoch 18, CIFAR-10 Batch 1:  validation accuracy 0.6258000135421753 validation loss 1.0744234323501587\n",
      "Epoch 18, CIFAR-10 Batch 2:  validation accuracy 0.6227999925613403 validation loss 1.0604370832443237\n",
      "Epoch 18, CIFAR-10 Batch 3:  validation accuracy 0.6322000026702881 validation loss 1.0338550806045532\n",
      "Epoch 18, CIFAR-10 Batch 4:  validation accuracy 0.6277999877929688 validation loss 1.0616384744644165\n",
      "Epoch 18, CIFAR-10 Batch 5:  validation accuracy 0.6287999749183655 validation loss 1.0515613555908203\n",
      "Epoch 19, CIFAR-10 Batch 1:  validation accuracy 0.6255999803543091 validation loss 1.0798845291137695\n",
      "Epoch 19, CIFAR-10 Batch 2:  validation accuracy 0.6322000026702881 validation loss 1.0400201082229614\n",
      "Epoch 19, CIFAR-10 Batch 3:  validation accuracy 0.6323999762535095 validation loss 1.044426441192627\n",
      "Epoch 19, CIFAR-10 Batch 4:  validation accuracy 0.626800000667572 validation loss 1.0644621849060059\n",
      "Epoch 19, CIFAR-10 Batch 5:  validation accuracy 0.6413999795913696 validation loss 1.017447829246521\n",
      "Epoch 20, CIFAR-10 Batch 1:  validation accuracy 0.6294000148773193 validation loss 1.0755832195281982\n",
      "Epoch 20, CIFAR-10 Batch 2:  validation accuracy 0.6240000128746033 validation loss 1.0617707967758179\n",
      "Epoch 20, CIFAR-10 Batch 3:  validation accuracy 0.6425999999046326 validation loss 1.0336484909057617\n",
      "Epoch 20, CIFAR-10 Batch 4:  validation accuracy 0.6349999904632568 validation loss 1.0398662090301514\n",
      "Epoch 20, CIFAR-10 Batch 5:  validation accuracy 0.6327999830245972 validation loss 1.0461660623550415\n",
      "Epoch 21, CIFAR-10 Batch 1:  validation accuracy 0.6284000277519226 validation loss 1.0775220394134521\n",
      "Epoch 21, CIFAR-10 Batch 2:  validation accuracy 0.633400022983551 validation loss 1.0485520362854004\n",
      "Epoch 21, CIFAR-10 Batch 3:  validation accuracy 0.6384000182151794 validation loss 1.0186583995819092\n",
      "Epoch 21, CIFAR-10 Batch 4:  validation accuracy 0.6272000074386597 validation loss 1.062211275100708\n",
      "Epoch 21, CIFAR-10 Batch 5:  validation accuracy 0.6377999782562256 validation loss 1.0273951292037964\n",
      "Epoch 22, CIFAR-10 Batch 1:  validation accuracy 0.6514000296592712 validation loss 1.0142931938171387\n",
      "Epoch 22, CIFAR-10 Batch 2:  validation accuracy 0.642799973487854 validation loss 1.0253009796142578\n",
      "Epoch 22, CIFAR-10 Batch 3:  validation accuracy 0.6431999802589417 validation loss 1.0265957117080688\n",
      "Epoch 22, CIFAR-10 Batch 4:  validation accuracy 0.6344000101089478 validation loss 1.0378978252410889\n",
      "Epoch 22, CIFAR-10 Batch 5:  validation accuracy 0.6348000168800354 validation loss 1.0352085828781128\n",
      "Epoch 23, CIFAR-10 Batch 1:  validation accuracy 0.647599995136261 validation loss 1.0182815790176392\n",
      "Epoch 23, CIFAR-10 Batch 2:  validation accuracy 0.6456000208854675 validation loss 1.0093162059783936\n",
      "Epoch 23, CIFAR-10 Batch 3:  validation accuracy 0.6492000222206116 validation loss 0.9959239959716797\n",
      "Epoch 23, CIFAR-10 Batch 4:  validation accuracy 0.6335999965667725 validation loss 1.0281898975372314\n",
      "Epoch 23, CIFAR-10 Batch 5:  validation accuracy 0.6395999789237976 validation loss 1.0257691144943237\n",
      "Epoch 24, CIFAR-10 Batch 1:  validation accuracy 0.6370000243186951 validation loss 1.058951497077942\n",
      "Epoch 24, CIFAR-10 Batch 2:  validation accuracy 0.6492000222206116 validation loss 1.0140589475631714\n",
      "Epoch 24, CIFAR-10 Batch 3:  validation accuracy 0.6589999794960022 validation loss 0.9852759838104248\n",
      "Epoch 24, CIFAR-10 Batch 4:  validation accuracy 0.6317999958992004 validation loss 1.0618889331817627\n",
      "Epoch 24, CIFAR-10 Batch 5:  validation accuracy 0.646399974822998 validation loss 1.013106107711792\n",
      "Epoch 25, CIFAR-10 Batch 1:  validation accuracy 0.6485999822616577 validation loss 1.0192487239837646\n",
      "Epoch 25, CIFAR-10 Batch 2:  validation accuracy 0.6439999938011169 validation loss 1.029750943183899\n",
      "Epoch 25, CIFAR-10 Batch 3:  validation accuracy 0.6466000080108643 validation loss 1.0106714963912964\n",
      "Epoch 25, CIFAR-10 Batch 4:  validation accuracy 0.6413999795913696 validation loss 1.0372192859649658\n",
      "Epoch 25, CIFAR-10 Batch 5:  validation accuracy 0.6345999836921692 validation loss 1.0444064140319824\n",
      "Epoch 26, CIFAR-10 Batch 1:  validation accuracy 0.6431999802589417 validation loss 1.0475267171859741\n",
      "Epoch 26, CIFAR-10 Batch 2:  validation accuracy 0.6467999815940857 validation loss 1.0300654172897339\n",
      "Epoch 26, CIFAR-10 Batch 3:  validation accuracy 0.6389999985694885 validation loss 1.006060004234314\n",
      "Epoch 26, CIFAR-10 Batch 4:  validation accuracy 0.6480000019073486 validation loss 1.013885736465454\n",
      "Epoch 26, CIFAR-10 Batch 5:  validation accuracy 0.6466000080108643 validation loss 1.012323260307312\n",
      "Epoch 27, CIFAR-10 Batch 1:  validation accuracy 0.6543999910354614 validation loss 1.0077507495880127\n",
      "Epoch 27, CIFAR-10 Batch 2:  validation accuracy 0.649399995803833 validation loss 1.0090025663375854\n",
      "Epoch 27, CIFAR-10 Batch 3:  validation accuracy 0.6367999911308289 validation loss 1.039824366569519\n",
      "Epoch 27, CIFAR-10 Batch 4:  validation accuracy 0.6442000269889832 validation loss 1.0163718461990356\n",
      "Epoch 27, CIFAR-10 Batch 5:  validation accuracy 0.6528000235557556 validation loss 0.9997379779815674\n",
      "Epoch 28, CIFAR-10 Batch 1:  validation accuracy 0.6611999869346619 validation loss 0.9820446968078613\n",
      "Epoch 28, CIFAR-10 Batch 2:  validation accuracy 0.6521999835968018 validation loss 1.0075011253356934\n",
      "Epoch 28, CIFAR-10 Batch 3:  validation accuracy 0.6480000019073486 validation loss 1.0117069482803345\n",
      "Epoch 28, CIFAR-10 Batch 4:  validation accuracy 0.6553999781608582 validation loss 1.0007535219192505\n",
      "Epoch 28, CIFAR-10 Batch 5:  validation accuracy 0.6514000296592712 validation loss 1.0104724168777466\n",
      "Epoch 29, CIFAR-10 Batch 1:  validation accuracy 0.6697999835014343 validation loss 0.9784385561943054\n",
      "Epoch 29, CIFAR-10 Batch 2:  validation accuracy 0.6585999727249146 validation loss 0.9896364212036133\n",
      "Epoch 29, CIFAR-10 Batch 3:  validation accuracy 0.65420001745224 validation loss 1.0014928579330444\n",
      "Epoch 29, CIFAR-10 Batch 4:  validation accuracy 0.6503999829292297 validation loss 0.9981861114501953\n",
      "Epoch 29, CIFAR-10 Batch 5:  validation accuracy 0.6614000201225281 validation loss 0.9977566599845886\n",
      "Epoch 30, CIFAR-10 Batch 1:  validation accuracy 0.6547999978065491 validation loss 1.0068670511245728\n",
      "Epoch 30, CIFAR-10 Batch 2:  validation accuracy 0.6633999943733215 validation loss 0.9787592887878418\n",
      "Epoch 30, CIFAR-10 Batch 3:  validation accuracy 0.6517999768257141 validation loss 1.0195285081863403\n",
      "Epoch 30, CIFAR-10 Batch 4:  validation accuracy 0.6424000263214111 validation loss 1.0395478010177612\n",
      "Epoch 30, CIFAR-10 Batch 5:  validation accuracy 0.6660000085830688 validation loss 0.9800259470939636\n",
      "Epoch 31, CIFAR-10 Batch 1:  validation accuracy 0.6646000146865845 validation loss 0.9845914840698242\n",
      "Epoch 31, CIFAR-10 Batch 2:  validation accuracy 0.6696000099182129 validation loss 0.9715577363967896\n",
      "Epoch 31, CIFAR-10 Batch 3:  validation accuracy 0.6424000263214111 validation loss 1.0299808979034424\n",
      "Epoch 31, CIFAR-10 Batch 4:  validation accuracy 0.6575999855995178 validation loss 0.992104709148407\n",
      "Epoch 31, CIFAR-10 Batch 5:  validation accuracy 0.63919997215271 validation loss 1.0206035375595093\n",
      "Epoch 32, CIFAR-10 Batch 1:  validation accuracy 0.659600019454956 validation loss 0.9837921857833862\n",
      "Epoch 32, CIFAR-10 Batch 2:  validation accuracy 0.6384000182151794 validation loss 1.0621525049209595\n",
      "Epoch 32, CIFAR-10 Batch 3:  validation accuracy 0.6583999991416931 validation loss 0.9863347411155701\n",
      "Epoch 32, CIFAR-10 Batch 4:  validation accuracy 0.6675999760627747 validation loss 0.9734390377998352\n",
      "Epoch 32, CIFAR-10 Batch 5:  validation accuracy 0.6679999828338623 validation loss 0.9665692448616028\n",
      "Epoch 33, CIFAR-10 Batch 1:  validation accuracy 0.6714000105857849 validation loss 0.968039870262146\n",
      "Epoch 33, CIFAR-10 Batch 2:  validation accuracy 0.6525999903678894 validation loss 1.008021354675293\n",
      "Epoch 33, CIFAR-10 Batch 3:  validation accuracy 0.6525999903678894 validation loss 0.9955814480781555\n",
      "Epoch 33, CIFAR-10 Batch 4:  validation accuracy 0.6603999733924866 validation loss 1.009945273399353\n",
      "Epoch 33, CIFAR-10 Batch 5:  validation accuracy 0.6571999788284302 validation loss 0.9873208999633789\n",
      "Epoch 34, CIFAR-10 Batch 1:  validation accuracy 0.6610000133514404 validation loss 0.9976959824562073\n",
      "Epoch 34, CIFAR-10 Batch 2:  validation accuracy 0.6650000214576721 validation loss 0.9796528220176697\n",
      "Epoch 34, CIFAR-10 Batch 3:  validation accuracy 0.6642000079154968 validation loss 0.999930739402771\n",
      "Epoch 34, CIFAR-10 Batch 4:  validation accuracy 0.6597999930381775 validation loss 0.9778285026550293\n",
      "Epoch 34, CIFAR-10 Batch 5:  validation accuracy 0.6628000140190125 validation loss 0.9881487488746643\n",
      "Epoch 35, CIFAR-10 Batch 1:  validation accuracy 0.6611999869346619 validation loss 0.9889647364616394\n",
      "Epoch 35, CIFAR-10 Batch 2:  validation accuracy 0.6697999835014343 validation loss 0.9707787036895752\n",
      "Epoch 35, CIFAR-10 Batch 3:  validation accuracy 0.6647999882698059 validation loss 0.973533034324646\n",
      "Epoch 35, CIFAR-10 Batch 4:  validation accuracy 0.6638000011444092 validation loss 0.9884713888168335\n",
      "Epoch 35, CIFAR-10 Batch 5:  validation accuracy 0.6690000295639038 validation loss 0.958335816860199\n",
      "Epoch 36, CIFAR-10 Batch 1:  validation accuracy 0.6593999862670898 validation loss 1.0099267959594727\n",
      "Epoch 36, CIFAR-10 Batch 2:  validation accuracy 0.6639999747276306 validation loss 0.9978490471839905\n",
      "Epoch 36, CIFAR-10 Batch 3:  validation accuracy 0.6651999950408936 validation loss 0.9824854731559753\n",
      "Epoch 36, CIFAR-10 Batch 4:  validation accuracy 0.6660000085830688 validation loss 0.9699800610542297\n",
      "Epoch 36, CIFAR-10 Batch 5:  validation accuracy 0.6628000140190125 validation loss 1.004624843597412\n",
      "Epoch 37, CIFAR-10 Batch 1:  validation accuracy 0.6546000242233276 validation loss 0.9897909164428711\n",
      "Epoch 37, CIFAR-10 Batch 2:  validation accuracy 0.6531999707221985 validation loss 1.009041428565979\n",
      "Epoch 37, CIFAR-10 Batch 3:  validation accuracy 0.6693999767303467 validation loss 0.9789903163909912\n",
      "Epoch 37, CIFAR-10 Batch 4:  validation accuracy 0.6614000201225281 validation loss 1.001401662826538\n",
      "Epoch 37, CIFAR-10 Batch 5:  validation accuracy 0.6629999876022339 validation loss 0.9927142858505249\n",
      "Epoch 38, CIFAR-10 Batch 1:  validation accuracy 0.6674000024795532 validation loss 0.9946738481521606\n",
      "Epoch 38, CIFAR-10 Batch 2:  validation accuracy 0.6773999929428101 validation loss 0.969900369644165\n",
      "Epoch 38, CIFAR-10 Batch 3:  validation accuracy 0.6743999719619751 validation loss 0.963036298751831\n",
      "Epoch 38, CIFAR-10 Batch 4:  validation accuracy 0.6646000146865845 validation loss 0.9861403107643127\n",
      "Epoch 38, CIFAR-10 Batch 5:  validation accuracy 0.6611999869346619 validation loss 0.9897304773330688\n",
      "Epoch 39, CIFAR-10 Batch 1:  validation accuracy 0.6672000288963318 validation loss 0.9734484553337097\n",
      "Epoch 39, CIFAR-10 Batch 2:  validation accuracy 0.6812000274658203 validation loss 0.9467117190361023\n",
      "Epoch 39, CIFAR-10 Batch 3:  validation accuracy 0.6711999773979187 validation loss 0.9635962843894958\n",
      "Epoch 39, CIFAR-10 Batch 4:  validation accuracy 0.6583999991416931 validation loss 1.0158324241638184\n",
      "Epoch 39, CIFAR-10 Batch 5:  validation accuracy 0.6507999897003174 validation loss 1.0642552375793457\n",
      "Epoch 40, CIFAR-10 Batch 1:  validation accuracy 0.6525999903678894 validation loss 1.0118060111999512\n",
      "Epoch 40, CIFAR-10 Batch 2:  validation accuracy 0.676800012588501 validation loss 0.9619593620300293\n",
      "Epoch 40, CIFAR-10 Batch 3:  validation accuracy 0.6761999726295471 validation loss 0.9760792851448059\n",
      "Epoch 40, CIFAR-10 Batch 4:  validation accuracy 0.6679999828338623 validation loss 0.9803564548492432\n",
      "Epoch 40, CIFAR-10 Batch 5:  validation accuracy 0.6664000153541565 validation loss 0.9912802577018738\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6682159810126582\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhL9PwfZ1VbJQgPPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1182aca90>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
